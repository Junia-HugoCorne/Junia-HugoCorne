{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdYLFhM6LvGg"
      },
      "source": [
        "Objectifs :\n",
        "- Implémenter le bag of word ;\n",
        "- Implémenter le TF-IDF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1gxaxo8M1hq"
      },
      "source": [
        "## Importations des packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO5tMjlUM06N",
        "outputId": "7d377023-2189-4a8b-adf8-46f68d7e3502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.text import Text\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq18nvqWM8Lu"
      },
      "source": [
        "## Importations des données\n",
        "\n",
        "Les données sont issue de [cette base de données](https://cs.nyu.edu/~kcho/DMQA/).\n",
        "\n",
        "Maintenant que nos outils sont chargés, nous allons charger nos données.\n",
        "\n",
        "Cliquez sur le lien ci-dessous :\n",
        "\n",
        "https://drive.google.com/drive/folders/12OmusfAUOcoLOCwEc--nfkKQ5eEozU45?usp=sharing\n",
        "\n",
        "Cliquer droit sur le dossier data et appuyer sur ajouter à mon drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dAmPai6M7wA",
        "outputId": "10e028a2-3132-43e6-d651-8d24e42f8a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYiTdYvFNF3J"
      },
      "source": [
        "Les données sont maintenant dans votre environnement collab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmk_Nlc2NJ7p",
        "outputId": "29d2047f-24c6-4da2-8d7d-4b4a44a1f99e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "print(os.listdir('gdrive/MyDrive/Exercice_1/Partie_1')[:10])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0a3ff2f0a147c158845afa44d2a012064896566b.story', '0a3fff5779a8f7cfdde5d284a429ab89fd5e85df.story', '0a0f56ebc5a0a67ed18de79d99b40a42d8058d04.story', '0a3ad75d92c5bc2eccf2763df86afe5ddeffed75.story', '0a3f2400ba4e5cdf4b3638ae6fb60fdfa12a2680.story', '0a3f567efff9f0748b2758c9e8c17dc66beade04.story', '0a05b14962b2e73bbff82086762e0e23d32b359f.story', '0a1ad82d161d90d758240407cb8c8fcebff4a212.story', '0a4ec4d37683347ca62b53982d2c5f4efb86f444.story', '0a4b2d4ea5fb0625e3e747525062f0a85345e4df.story']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PC-_PGWtn0D"
      },
      "source": [
        "# Création de la base de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4Q4GATMtpsz"
      },
      "source": [
        "cmpt = 0\n",
        "dict_data = dict()\n",
        "\n",
        "for file_name in os.listdir('gdrive/MyDrive/Exercice_1/Partie_1'):\n",
        "    f = open('gdrive/MyDrive/Exercice_1/Partie_1/'+file_name, 'r')\n",
        "    lst = \"\"\n",
        "    for line in f:\n",
        "\n",
        "       line.strip()\n",
        "       line = line.replace(\"\\n\" ,'')\n",
        "       line = line.replace(\"//\" , '')\n",
        "       line = line.replace(\"/\" , '')\n",
        "       if len(line) > 0 :\n",
        "        lst += line\n",
        "\n",
        "    dict_data[cmpt] = lst\n",
        "    cmpt += 1\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoHCpAp5vrLn"
      },
      "source": [
        "# Prétraitements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqyhQF-DvX2B"
      },
      "source": [
        "## En minuscule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZHDj0xsvZxy"
      },
      "source": [
        "dict_data_min = dict()\n",
        "for k, v in dict_data.items():\n",
        "  dict_data_min[k] = v.lower()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXLT8VOavcY0"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfBQd71VvgP0"
      },
      "source": [
        "dict_data_token = dict()\n",
        "for k, v in dict_data_min.items():\n",
        "  tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(v)\n",
        "  dict_data_token[k] = tokens"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxbEUZU_wEF2"
      },
      "source": [
        "## Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJoHkqjkwHGk"
      },
      "source": [
        "dict_data_stop = dict()\n",
        "for k, v in dict_data_token.items():\n",
        "  dict_data_stop[k] = [w for w in v if not w in list(nltk.corpus.stopwords.words())]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpo8jDw8vh2B"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR4hmThDvmrG"
      },
      "source": [
        "dict_data_stem = dict()\n",
        "st = LancasterStemmer()\n",
        "\n",
        "for index, doc in dict_data_stop.items():\n",
        "  dict_data_stem[index] = [st.stem(w) for w in doc ]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of words"
      ],
      "metadata": {
        "id": "8OarYLlTg9DZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vecteur de vocabulaire"
      ],
      "metadata": {
        "id": "yN3ywXveg-a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "\n",
        "for index, doc in dict_data_stem.items():\n",
        "  for word in doc :\n",
        "    vocab.add(word)\n",
        "\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "id": "LxBsVhlNhAq7",
        "outputId": "0fa6c418-e102-4b7b-a87a-9e5c0d433f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of words"
      ],
      "metadata": {
        "id": "vlSvSVPZhBor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Création du Bag of Words pour chaque document\n",
        "bow_documents = {}\n",
        "\n",
        "for index, doc in dict_data_stem.items():\n",
        "    # Construire le vocabulaire pour le document\n",
        "    # vocab = set(doc) # The problem is here - vocab is a set\n",
        "    vocab = list(set(doc))  # Convert vocab to a list\n",
        "\n",
        "    # Initialiser un DataFrame avec le vocabulaire du document\n",
        "    data = pd.DataFrame(0, index=[index], columns=vocab)\n",
        "\n",
        "    # Remplir le Bag of Words pour ce document\n",
        "    for word in doc:\n",
        "        data.loc[index, word] += 1\n",
        "\n",
        "    # Ajouter au dictionnaire des résultats\n",
        "    bow_documents[index] = data\n",
        "\n",
        "# Afficher les Bag of Words pour chaque document\n",
        "for doc_id, bow in bow_documents.items():\n",
        "    print(f\"\\nBag of Words pour le document {doc_id} :\")\n",
        "    print(bow)"
      ],
      "metadata": {
        "id": "K_vW_tfZWdhT",
        "outputId": "8e5887d8-3674-4079-e382-438dfbcf00a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words pour le document 0 :\n",
            "   threatened  hostess  clos  correct  lovin  rel  ireport  1985  ap  al  ...  \\\n",
            "0           1        1     1        1      1    1        1     1   2   1  ...   \n",
            "\n",
            "   solo  firearm  disagree  1970s  truc  calib  ask  ago  spect  just  \n",
            "0     1        3         1      1     1      1    1    1     23     2  \n",
            "\n",
            "[1 rows x 288 columns]\n",
            "\n",
            "Bag of Words pour le document 1 :\n",
            "   145  read  cov  break  distribut  spin  act  bant  pag  calder  ...  morn  \\\n",
            "1    2     2    1      1          1     2    1     1    1       2  ...     1   \n",
            "\n",
            "   aw  fox  forc  lat  big  caus  continu  april  control  \n",
            "1   2    1     7    1    1     1        1      1        2  \n",
            "\n",
            "[1 rows x 249 columns]\n",
            "\n",
            "Bag of Words pour le document 2 :\n",
            "   sec  weapon  nassau  pict  act  column  emmy  send  video  low  ...  \\\n",
            "2    2       1       1     1    1       1     1     1      1    1  ...   \n",
            "\n",
            "   cameram  auth  wid  roy  caus  car  continu  april  30th  thing  \n",
            "2        1     1    1    9     1    6        2      2     1      1  \n",
            "\n",
            "[1 rows x 155 columns]\n",
            "\n",
            "Bag of Words pour le document 3 :\n",
            "   sec  read  break  pict  act  provid  fir  stand  saf  agr  ...  absolv  \\\n",
            "3    3     3      1     1    2       1    1      1    1    2  ...       1   \n",
            "\n",
            "   auth  detail  forc  hond  pres  unit  reappear  transf  just  \n",
            "3     1       1     1     6     1     2         1       1     1  \n",
            "\n",
            "[1 rows x 245 columns]\n",
            "\n",
            "Bag of Words pour le document 4 :\n",
            "   job  sav  act  pict  2009  improv  fut  rol  back  decid  ...  receiv  \\\n",
            "4   10    2    5     1     3       1    1    1     2      1  ...       1   \n",
            "\n",
            "   challeng  reimburs  pri  auth  forc  fellow  forev  wel  voic  \n",
            "4         1         2    2     4     1       1      1    1     1  \n",
            "\n",
            "[1 rows x 329 columns]\n",
            "\n",
            "Bag of Words pour le document 5 :\n",
            "   chief  aid  job  2002  boehn  2006  correct  clos  rel  numb  ...  bring  \\\n",
            "5      8    1    1     1      2     2        1     1    2     2  ...      2   \n",
            "\n",
            "   fellow  gerg  car  ago  cho  blunt  thing  weigh  appoint  \n",
            "5       2     2    3    1    6      1      4      1        1  \n",
            "\n",
            "[1 rows x 220 columns]\n",
            "\n",
            "Bag of Words pour le document 6 :\n",
            "   read  job  clos  correct  priv  rel  prev  alask  cli  capit  ...  account  \\\n",
            "6     1    1     3        2     1    1     1      5    1      1  ...        1   \n",
            "\n",
            "   ful  child  ask  conv  join  continu  car  thing  17  \n",
            "6    4      3    2     1     1        1    1      1   1  \n",
            "\n",
            "[1 rows x 278 columns]\n",
            "\n",
            "Bag of Words pour le document 7 :\n",
            "   break  embark  etern  ideolog  promin  party  back  world  lin  trig  ...  \\\n",
            "7      1       2      1        3       2      3     1      4    2     1  ...   \n",
            "\n",
            "   decl  3  led  1980s  wear  challeng  gap  conserv  revolv  caus  \n",
            "7     1  1    1      1     1         1    1        1       1     1  \n",
            "\n",
            "[1 rows x 361 columns]\n",
            "\n",
            "Bag of Words pour le document 8 :\n",
            "   read  cov  highlightit  idaho  nuclear  numb  surg  unsuccess  path  ext  \\\n",
            "8     1    1            1      1        1     2     1          1     1    1   \n",
            "\n",
            "   ...  forc  account  doctrin  voic  simil  clear  control  just  \\\n",
            "8  ...     1        1        1     1      1      1        1     1   \n",
            "\n",
            "   highlightzel  17  \n",
            "8             2   1  \n",
            "\n",
            "[1 rows x 272 columns]\n",
            "\n",
            "Bag of Words pour le document 9 :\n",
            "   aid  sew  cov  jungl  ireport  stand  flo  capit  emblazon  komp  ...  ful  \\\n",
            "9    1    1    1      1        1      1    3      1         1     1  ...    1   \n",
            "\n",
            "   meal  collaps  victim  compos  unit  medsh  skeleton  30th  thing  \n",
            "9     1        2       1       1     1      1         2     1      1  \n",
            "\n",
            "[1 rows x 273 columns]\n",
            "\n",
            "Bag of Words pour le document 10 :\n",
            "    chief  poign  highlightmartin  blew  sev  blast  pul  annount  low  skul  \\\n",
            "10      1      1                1     1    2      1    1        3    1     1   \n",
            "\n",
            "    ...  morn  bomb  2005  compet  opportun  52  london  volleybal  brit  \\\n",
            "10  ...     2     7     2       2         2   1       9         10     4   \n",
            "\n",
            "    martin  \n",
            "10       1  \n",
            "\n",
            "[1 rows x 159 columns]\n",
            "\n",
            "Bag of Words pour le document 11 :\n",
            "    job  rand  nuclear  act  transit  strong  ivo  improv  duck  beef  ...  \\\n",
            "11    1     2        4    1        1       1    1       2     1     1  ...   \n",
            "\n",
            "    stim  challeng  expand  redefin  pri  gen  auth  albright  forc  wrap  \n",
            "11     1         1       2        1    3    1     1         1     4     1  \n",
            "\n",
            "[1 rows x 347 columns]\n",
            "\n",
            "Bag of Words pour le document 12 :\n",
            "    chief  william  ment  saf  video  bean  rough  point  spec  feet  ...  \\\n",
            "12      2        1     2    1      1     1      1      1     1     3  ...   \n",
            "\n",
            "    tan  9  morn  auth  alleg  county  car  alexand  tip  weigh  \n",
            "12    2  3     1     3      2       1    1        2    1      3  \n",
            "\n",
            "[1 rows x 166 columns]\n",
            "\n",
            "Bag of Words pour le document 13 :\n",
            "    sec  aid  interim  provid  fir  agr  send  monit  immedy  are  ...  unisf  \\\n",
            "13    4    1        1       1    1    3     1      2       1    1  ...      1   \n",
            "\n",
            "    stat  sign  50  forc  peacekeep  unfet  unit  approv  ago  \n",
            "13     5     2   1     3          4      1     2       1    1  \n",
            "\n",
            "[1 rows x 102 columns]\n",
            "\n",
            "Bag of Words pour le document 14 :\n",
            "    underground  prev  discov  tre  told  fut  link  shut  addict  arabiy  \\\n",
            "14            1     1       1    1     3    1     1     1       1       1   \n",
            "\n",
            "    ...  plac  stat  night  auth  zikiry  alleg  shock  child  continu  deep  \n",
            "14  ...     2     1      1     1       1      1      1      1        1     1  \n",
            "\n",
            "[1 rows x 96 columns]\n",
            "\n",
            "Bag of Words pour le document 15 :\n",
            "    day  air  mil  provid  show  fleet  hous  blast  plan  highlightth  ...  \\\n",
            "15    1    1    1       1     1      2     2      1     1            1  ...   \n",
            "\n",
            "    intern  13  cheap  ag  spacewalk  includ  muse  scheduled  spac  febru  \n",
            "15       2   1      1   1          1       1     1          1    10      2  \n",
            "\n",
            "[1 rows x 51 columns]\n",
            "\n",
            "Bag of Words pour le document 16 :\n",
            "    bil  sew  1895  job  rel  instal  numb  sev  act  distribut  ...  keep  \\\n",
            "16    1    1     2    1    3       1     1    1    3          1  ...     2   \n",
            "\n",
            "    highlightnoa  pres  research  shift  caus  dioxid  continu  predict  you  \n",
            "16             1     1         1      1     2       2        3        1    1  \n",
            "\n",
            "[1 rows x 234 columns]\n",
            "\n",
            "Bag of Words pour le document 17 :\n",
            "    holidaynot  break  rel  look  lopilato  capit  fun  bueno  guest  nerv  \\\n",
            "17           1      1    1     1         4      1    1      1      1     1   \n",
            "\n",
            "    ...  gear  bublé  tim  tot  actress  entertain  high  night  ful  air  \n",
            "17  ...     1      4    1    1        2          1     1      3    1    1  \n",
            "\n",
            "[1 rows x 97 columns]\n",
            "\n",
            "Bag of Words pour le document 18 :\n",
            "    levin  scen  ticket  pursuit  distribut  continu  pict  erupt  act  fir  \\\n",
            "18      1     1       1        1          1        1     3      1    1    2   \n",
            "\n",
            "    ...  upro  nar  lat  caus  mock  hot  company  blunt  lobby  form  \n",
            "18  ...     2    1    1     1     1    3        1      1      1     1  \n",
            "\n",
            "[1 rows x 222 columns]\n",
            "\n",
            "Bag of Words pour le document 19 :\n",
            "    job  read  cov  achiev  2009  contribut  empow  cairo  cre  emir  ...  \\\n",
            "19    1     1    1       3     1          2      2      1    1     3  ...   \n",
            "\n",
            "    gen  raf  pres  ful  child  background  unit  car  ago  form  \n",
            "19    2    1     1    1      1           1     3    1    1     2  \n",
            "\n",
            "[1 rows x 180 columns]\n",
            "\n",
            "Bag of Words pour le document 20 :\n",
            "    sec  read  antipathy  act  capit  masha  animos  observ  right  shot  ...  \\\n",
            "20    1     1          1    1      3      1       1       1      1     1  ...   \n",
            "\n",
            "    calm  tit  death  unit  valid  simil  embrac  tripk  sun  deep  \n",
            "20     1    1      1     1      1      1       1      1    1     1  \n",
            "\n",
            "[1 rows x 292 columns]\n",
            "\n",
            "Bag of Words pour le document 21 :\n",
            "    chief  jack  bil  sav  250  highlightsom  profit  motorstorm  600  cur  \\\n",
            "21      1     1    1    1    2             1       1           1    1    2   \n",
            "\n",
            "    ...  account  big  ultim  minim  unit  outsold  company  unfamili  \\\n",
            "21  ...        1    1      1      1     2        1        1         1   \n",
            "\n",
            "    control  17  \n",
            "21        1   1  \n",
            "\n",
            "[1 rows x 200 columns]\n",
            "\n",
            "Bag of Words pour le document 22 :\n",
            "    bil  cov  integr  itun  priv  ap  act  gloss  lip  breadstick  ...  \\\n",
            "22    1    1       1     1     1   2    1      1    1           1  ...   \n",
            "\n",
            "    launch  smoothy  resta  envelop  wid  load  unit  untap  company  subscrib  \n",
            "22       1        1      1        1    1     1     3      1        5         1  \n",
            "\n",
            "[1 rows x 183 columns]\n",
            "\n",
            "Bag of Words pour le document 23 :\n",
            "    read  scen  hip  uk  break  casualwear  integr  spin  distribut  zimbabw  \\\n",
            "23     2     1    1   1      1           1       1     1          2        1   \n",
            "\n",
            "    ...  hug  apprecy  bring  wid  ademiluy  big  moof  london  sexy  deep  \n",
            "23  ...    1        1      1    1         3    1     1       2     1     1  \n",
            "\n",
            "[1 rows x 218 columns]\n",
            "\n",
            "Bag of Words pour le document 24 :\n",
            "    job  clos  act  beg  stand  saf  pul  contribut  shot  feet  ...  \\\n",
            "24    1     1    1    1      1    2    1          2     3     3  ...   \n",
            "\n",
            "    difficult  night  auth  50  fellow  compet  socy  margaret  car  wild  \n",
            "24          1      2     2   1       1       1     1         1    1     1  \n",
            "\n",
            "[1 rows x 148 columns]\n",
            "\n",
            "Bag of Words pour le document 25 :\n",
            "    devont  al  ral  bowl  216  period  cur  feat  tre  point  ...  cody  \\\n",
            "25       1   1    3     1    1       1    1     1    1      3  ...     1   \n",
            "\n",
            "    halftim  sery  stat  fin  kelvin  22  leadaft  auburn  form  \n",
            "25        2     1     4    3       1   1        1       3     1  \n",
            "\n",
            "[1 rows x 148 columns]\n",
            "\n",
            "Bag of Words pour le document 26 :\n",
            "    sav  unsuccess  wiggl  numb  act  pict  novost  fut  east  com  ...  \\\n",
            "26    1          1      1     1    1     1       1    1     1    1  ...   \n",
            "\n",
            "    const  peg  pri  provint  gen  auth  jerem  detail  forc  predict  \n",
            "26      1    1    1        2    1     1      1       1     5        1  \n",
            "\n",
            "[1 rows x 361 columns]\n",
            "\n",
            "Bag of Words pour le document 27 :\n",
            "    sec  blew  sev  al  dea  pop  tre  low  contribut  storm  ...  garb  caus  \\\n",
            "27    1     1    1   1    1    1    1    2          1      4  ...     1     1   \n",
            "\n",
            "    death  county  car  remn  predict  highlightrainfal  flash  body  \n",
            "27      1       3    1     2        1                 1      4     1  \n",
            "\n",
            "[1 rows x 210 columns]\n",
            "\n",
            "Bag of Words pour le document 28 :\n",
            "    blew  band  clos  sev  pol  pict  dark  show  gird  unharm  ...  cheap  \\\n",
            "28     1     6     1    3    1     1     1     1     1       1  ...      3   \n",
            "\n",
            "    met  report  collaps  driv  includ  confirm  concert  rock  overcast  \n",
            "28    1       1        2     1       1        1        1     1         1  \n",
            "\n",
            "[1 rows x 59 columns]\n",
            "\n",
            "Bag of Words pour le document 29 :\n",
            "    sec  abs  clos  break  angry  unsuccess  rel  numb  prev  act  ...  gang  \\\n",
            "29    2    1     1      1      1          1    4     1     2    2  ...     1   \n",
            "\n",
            "    detail  forc  lat  beid  ask  car  continu  control  17  \n",
            "29       1     2    2     4    1    1        3        1   1  \n",
            "\n",
            "[1 rows x 206 columns]\n",
            "\n",
            "Bag of Words pour le document 30 :\n",
            "    sec  prelimin  ess  peac  newspap  mov  saturday  northern  \\\n",
            "30    1         1    2     1        1    3         1         3   \n",
            "\n",
            "    highlightgovern  govern  ...  min  cnn  azawad  left  stat  bring  forc  \\\n",
            "30                2       4  ...    2    1       4     1     4      1     2   \n",
            "\n",
            "    death  unit  join  \n",
            "30      1     1     1  \n",
            "\n",
            "[1 rows x 80 columns]\n",
            "\n",
            "Bag of Words pour le document 31 :\n",
            "    distribut  emy  1965  discov  energy  saf  highlights  send  pop  reduc  \\\n",
            "31          1    3     1       1       1    1           1     1    1      5   \n",
            "\n",
            "    ...  crimin  individ  shift  restrict  death  tobacco  ago  control  just  \\\n",
            "31  ...       6        1      1         4      1        4    1        2     1   \n",
            "\n",
            "    form  \n",
            "31     3  \n",
            "\n",
            "[1 rows x 243 columns]\n",
            "\n",
            "Bag of Words pour le document 32 :\n",
            "    job  act  ashl  com  answ  fac  myl  bolc  sol  lov  ...  3  custod  wear  \\\n",
            "32    2    2     2    2     2    2   12     1    1    2  ...  1       1     1   \n",
            "\n",
            "    prosecut  king  beat  high  auth  hot  herbert  \n",
            "32         1    13     2     1     7    1        4  \n",
            "\n",
            "[1 rows x 318 columns]\n",
            "\n",
            "Bag of Words pour le document 33 :\n",
            "    chief  cov  uk  instal  vit  provid  highlightblackfri  energy  lindsay  \\\n",
            "33      1    1   2       1    1       1                  1       2        1   \n",
            "\n",
            "    newm  ...  gen  largest  bring  50  manufact  individ  company  id  sun  \\\n",
            "33     1  ...    1        2      1   1         1        1        1   1    1   \n",
            "\n",
            "    complet  \n",
            "33        2  \n",
            "\n",
            "[1 rows x 113 columns]\n",
            "\n",
            "Bag of Words pour le document 34 :\n",
            "    hamrdl  bil  concess  1953  augy  clos  dec  priv  rel  nuclear  ...  \\\n",
            "34       1    3        1     2     1     1    1     4    1        1  ...   \n",
            "\n",
            "    beid  misunderstand  ask  unit  valid  london  background  id  martin  \\\n",
            "34     1              2    1     5      2       1           1   1       1   \n",
            "\n",
            "    form  \n",
            "34     3  \n",
            "\n",
            "[1 rows x 276 columns]\n",
            "\n",
            "Bag of Words pour le document 35 :\n",
            "    highlightit  richest  priv  rel  bicenten  act  220  worthwhil  beg  \\\n",
            "35            1        1     2    1         1    1    2          1    1   \n",
            "\n",
            "    capit  ...  gen  migr  2005  big  getty  county  unit  backlash  90  ago  \n",
            "35      1  ...    1     1     1    1      1       1     2         1   1    1  \n",
            "\n",
            "[1 rows x 274 columns]\n",
            "\n",
            "Bag of Words pour le document 36 :\n",
            "    key  spin  chil  fir  websit  low  shot  strong  ros  mickelson  ...  maj  \\\n",
            "36    1     1     1    1       2    1     2       1    1          4  ...    1   \n",
            "\n",
            "    highlightsw  65  fin  morn  keep  roy  control  brit  form  \n",
            "36            1   1    2     1     1    3        1     2     1  \n",
            "\n",
            "[1 rows x 119 columns]\n",
            "\n",
            "Bag of Words pour le document 37 :\n",
            "    sabin  priv  sev  ap  tre  germ  are  mov  long  45  ...  schumacher  \\\n",
            "37      1     1    2   1    1     1    1    1     2   1  ...           5   \n",
            "\n",
            "    team  mark  2012  tim  difficult  car  continu  rock  form  \n",
            "37     1     1     1    1          2    1        3     2     1  \n",
            "\n",
            "[1 rows x 80 columns]\n",
            "\n",
            "Bag of Words pour le document 38 :\n",
            "    job  citiesdemand  capit  gown  low  teach  highlightvisit  com  unlik  \\\n",
            "38    1             1      2     1    2      1               1    1      1   \n",
            "\n",
            "    urb  ...  apprecy  hug  auth  screen  steel  migr  forc  london  predict  \\\n",
            "38    8  ...        1    3     2       1      1     1     1       1        2   \n",
            "\n",
            "    complet  \n",
            "38        4  \n",
            "\n",
            "[1 rows x 381 columns]\n",
            "\n",
            "Bag of Words pour le document 39 :\n",
            "    bil  ring  cov  break  correct  priv  ment  continu  act  cli  ...  \\\n",
            "39    1     1    1      1        1     2     1        1    3    1  ...   \n",
            "\n",
            "    meritless  doe  big  assert  unfet  caus  child  victim  ago  id  \n",
            "39          2    1    1       1      1     2      4       4    2   2  \n",
            "\n",
            "[1 rows x 281 columns]\n",
            "\n",
            "Bag of Words pour le document 40 :\n",
            "    key  job  breakthrough  numb  steph  act  transport  policy  agr  keyston  \\\n",
            "40    1    1             1     1      1    1          1       1    2        4   \n",
            "\n",
            "    ...  account  nant  voic  unit  approv  join  control  highlightthr  \\\n",
            "40  ...        1     1     1     5       2     1        3             1   \n",
            "\n",
            "    pelos  form  \n",
            "40      1     1  \n",
            "\n",
            "[1 rows x 219 columns]\n",
            "\n",
            "Bag of Words pour le document 41 :\n",
            "    act  hyslop  pag  websit  video  carib  low  crazy  monit  peac  ...  \\\n",
            "41    1       1    1       1      2      1    1      1      1     2  ...   \n",
            "\n",
            "    clearw  wheel  big  exhaust  mh  baluch  ask  unit  clear  air  \n",
            "41       1      1    1        2   1      14    1     1      1    1  \n",
            "\n",
            "[1 rows x 156 columns]\n",
            "\n",
            "Bag of Words pour le document 42 :\n",
            "    job  vijay  act  capit  retrograd  septemb  promin  onlin  improv  \\\n",
            "42    1      1    1      4          1        1       1      1       1   \n",
            "\n",
            "    interest  ...  2012  redefin  pri  fed  gen  forc  jes  mock  voic  \\\n",
            "42         1  ...     1        1    1    1    1     1    1     1     1   \n",
            "\n",
            "    costolo  \n",
            "42        1  \n",
            "\n",
            "[1 rows x 324 columns]\n",
            "\n",
            "Bag of Words pour le document 43 :\n",
            "    key  act  policy  cur  send  video  point  possess  told  gam  ...  fbi  \\\n",
            "43    1    2       2    1     2      2      1        1     1    2  ...    1   \n",
            "\n",
            "    demand  tol  suspend  sign  alleg  forc  shock  minim  disgust  \n",
            "43       1    1        2     1      1     1      1      1        1  \n",
            "\n",
            "[1 rows x 87 columns]\n",
            "\n",
            "Bag of Words pour le document 44 :\n",
            "    aid  cov  priv  nuclear  act  provid  av  capit  weath  period  ...  \\\n",
            "44    4    1     1        1    1       1   1      1      1       1  ...   \n",
            "\n",
            "    suspend  50  highlightless  driest  reclud  missil  90  unit  continu  \\\n",
            "44        1   1              1       2       1       1   1     2        1   \n",
            "\n",
            "    april  \n",
            "44      1  \n",
            "\n",
            "[1 rows x 130 columns]\n",
            "\n",
            "Bag of Words pour le document 45 :\n",
            "    read  numb  act  pict  2009  teach  onlin  tetsuy  opt  com  ...  3  win  \\\n",
            "45     1     6    4     1     2      1      2       1    1    1  ...  9    1   \n",
            "\n",
            "    p  314  newcastl  salvad  9  high  auth  puzzl  \n",
            "45  1    1         1       1  3     1     1      1  \n",
            "\n",
            "[1 rows x 345 columns]\n",
            "\n",
            "Bag of Words pour le document 46 :\n",
            "    sec  read  disgruntl  aid  ring  perino  chief  lew  spin  wilson  ...  \\\n",
            "46    2     2          1    2     1       2      1    1     1       1  ...   \n",
            "\n",
            "    ultim  disingenu  wing  clear  puzzl  id  rov  thing  just  form  \n",
            "46      1          2     1      1      2   1    3      1     1    12  \n",
            "\n",
            "[1 rows x 238 columns]\n",
            "\n",
            "Bag of Words pour le document 47 :\n",
            "    telekom  numb  pict  provid  capit  memo  consolid  cur  geograph  2009  \\\n",
            "47        2     1     1       1      1     1         1    2         1     1   \n",
            "\n",
            "    ...  56  gen  largest  trail  amy  big  highlightby  approv  company  form  \n",
            "47  ...   2    1        3      1    1    1            1       1        2     2  \n",
            "\n",
            "[1 rows x 189 columns]\n",
            "\n",
            "Bag of Words pour le document 48 :\n",
            "    chief  job  afternoon  weapon  scen  aid  priv  ment  look  rel  ...  edg  \\\n",
            "48      2    1          1       3     1    1     1     1     1    1  ...    1   \n",
            "\n",
            "    firearm  forc  handgun  car  join  clear  calm  air  fak  \n",
            "48        3     1        1    6     1      1     1    3    2  \n",
            "\n",
            "[1 rows x 171 columns]\n",
            "\n",
            "Bag of Words pour le document 49 :\n",
            "    chief  bil  read  nuclear  senda  ap  act  energy  policy  saf  ...  ogur  \\\n",
            "49      1    1     1       18      1   1    1       6       2    9  ...     1   \n",
            "\n",
            "    rethink  assert  strictest  calcul  green  approv  company  height  body  \n",
            "49        1       1          1       1      1       2        3       1     1  \n",
            "\n",
            "[1 rows x 180 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YxVOQ3QBNqv6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}